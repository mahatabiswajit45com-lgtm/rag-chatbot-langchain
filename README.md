# ğŸ¤– AI Chatbot - Production Ready

A comprehensive AI chatbot with LangChain, ChromaDB, FastAPI, and Docker support.

## âœ¨ Features

- ğŸ’¬ **Chat with Memory** - Remembers conversation history
- ğŸ“„ **RAG (Document Q&A)** - Answer questions from your documents
- ğŸ¤– **AI Agent** - Uses tools (calculator, date, text processing)
- ğŸ”„ **Multi-Provider** - OpenAI & Anthropic support with fallback
- ğŸ³ **Docker Ready** - One command deployment
- ğŸ“Š **Session Management** - Persistent chat sessions

## ğŸš€ Quick Start

### 1. Clone & Setup

```bash
cd chatbot
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 2. Configure Environment

Edit `.env` file:
```env
OPENAI_API_KEY=sk-your-key-here
ANTHROPIC_API_KEY=sk-ant-your-key-here  # Optional
```

### 3. Run Server

```bash
uvicorn app.main:app --reload
```

Open: http://localhost:8000/docs

## ğŸ“– API Endpoints

### Chat Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/chat` | POST | Simple chat with memory |
| `/api/v1/chat/rag` | POST | Chat with document context |
| `/api/v1/chat/agent` | POST | Chat with AI agent (tools) |

### Document Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/documents/upload` | POST | Upload PDF/DOCX/TXT |
| `/api/v1/documents/add-text` | POST | Add raw text |
| `/api/v1/documents/stats/{name}` | GET | Collection stats |
| `/api/v1/documents/{name}` | DELETE | Delete collection |

### Session Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/sessions` | GET | List all sessions |
| `/api/v1/sessions/{id}` | GET | Get session history |
| `/api/v1/sessions/{id}` | DELETE | Delete session |

## ğŸ’¡ Usage Examples

### Simple Chat

```bash
curl -X POST http://localhost:8000/api/v1/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Hello! What is LangChain?"}'
```

### RAG Chat (Document Q&A)

```bash
# First upload a document
curl -X POST http://localhost:8000/api/v1/documents/upload \
  -F "file=@document.pdf" \
  -F "collection_name=my_docs"

# Then query it
curl -X POST http://localhost:8000/api/v1/chat/rag \
  -H "Content-Type: application/json" \
  -d '{"query": "What does the document say about AI?", "collection_name": "my_docs"}'
```

### Agent Chat (with Tools)

```bash
curl -X POST http://localhost:8000/api/v1/chat/agent \
  -H "Content-Type: application/json" \
  -d '{"message": "Calculate sqrt(144) + 25"}'
```

## ğŸ³ Docker Deployment

### Using Docker Compose (Recommended)

```bash
# Build and run
docker-compose up -d

# View logs
docker-compose logs -f

# Stop
docker-compose down
```

### Using Docker directly

```bash
# Build
docker build -t ai-chatbot .

# Run
docker run -d -p 8000:8000 \
  -e OPENAI_API_KEY=sk-xxx \
  ai-chatbot
```

## ğŸ“ Project Structure

```
chatbot/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py           # FastAPI app
â”‚   â”œâ”€â”€ api.py            # API endpoints
â”‚   â”œâ”€â”€ llm.py            # LLM configuration
â”‚   â”œâ”€â”€ prompt.py         # Prompt templates
â”‚   â”œâ”€â”€ memory.py         # Chat history
â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â”œâ”€â”€ loader.py     # Document loading
â”‚   â”‚   â”œâ”€â”€ splitter.py   # Text chunking
â”‚   â”‚   â”œâ”€â”€ embeddings.py # Vector embeddings
â”‚   â”‚   â””â”€â”€ vectorstore.py# ChromaDB
â”‚   â””â”€â”€ tools/
â”‚       â””â”€â”€ calculator.py # Agent tools
â”œâ”€â”€ data/                 # PDF storage
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ .env
```

## ğŸ› ï¸ Available Tools (Agent)

| Tool | Description |
|------|-------------|
| `calculator` | Math calculations |
| `get_current_datetime` | Current date/time |
| `calculate_date_difference` | Days between dates |
| `word_counter` | Text statistics |
| `text_transformer` | Text transformations |
| `json_formatter` | JSON formatting |
| `unit_converter` | Unit conversions |

## ğŸ”§ Configuration

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `OPENAI_API_KEY` | OpenAI API key | Required |
| `ANTHROPIC_API_KEY` | Anthropic API key | Optional |
| `DEFAULT_MODEL` | Default LLM model | gpt-4o-mini |
| `CHROMA_PERSIST_DIR` | ChromaDB storage | ./chroma_db |
| `HOST` | Server host | 0.0.0.0 |
| `PORT` | Server port | 8000 |

## ğŸ“š Key Concepts Learned

### LangChain
- LLM integration with multiple providers
- Prompt templates and management
- Conversation memory (buffer, window)
- Chains for complex workflows
- Agents with tool calling

### ChromaDB
- Vector embeddings storage
- Similarity search
- Document collections
- Persistence

### RAG (Retrieval Augmented Generation)
- Document loading (PDF, DOCX, TXT)
- Text chunking strategies
- Embedding generation
- Context retrieval for LLM

### FastAPI
- REST API design
- Request/Response models
- File uploads
- Error handling

### Docker
- Containerization
- Docker Compose
- Environment management
- Health checks

## ğŸš€ Next Steps

1. Add authentication (API keys)
2. Add rate limiting
3. Add Redis caching
4. Add streaming responses
5. Add more tools (web search, etc.)
6. Add frontend UI

## ğŸ“ License

MIT License - Built by Biswajit

---

Made with â¤ï¸ using LangChain, ChromaDB, FastAPI, and Docker
